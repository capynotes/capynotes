Good afternoon. So we will continue with process scheduling today. So any questions from the last lecture? Any questions that you might have from the last lecture? English please. Right, right. Yes, we can, we will discuss that, okay? So how can we know how long process we executed the CPU, right? So we will discuss that. Any other questions? Any other questions that you might have? Okay, so we will continue with scheduling. So we have seen one scheduling algorithm, right? First come, first served. So we will continue with other algorithms. So we have seen FCFS algorithm. So basically the idea was very simple. In a RedQ you can have several processes scheduled, right? You select the process that has arrived first to RedQ, okay? So this is first come, first served scheduling. So the process that comes first to RedQ is scheduled also first to the CPU, right? So the idea was very simple. It's very easy to implement the scheduling algorithm and we have computed how, what kind of waiting time we can have in such a system. We have computed the average waiting time. For example, here we have seen that the order of the processes in the RedQ actually makes a difference in the average waiting time for the processes. So if this is the order where we have a long job ahead of the shorter jobs, then the scheduling algorithm may yield an average waiting time which is 17 milliseconds, okay? However, if we have shorter jobs ahead of the longer job, then we can have a scheduling, we can have the scheduling algorithm providing an average waiting time which is just 3 milliseconds, okay? So the order of the processes makes a difference. So another scheduling algorithm is SJF algorithm. So in this algorithm what we do is we associate with each process the length of its next CPU burst, okay? So then assume we know the length of the next CPU burst for every process in the RedQ, then this algorithm selects the job or process that has the smallest next CPU burst, okay? So in this way we use the lengths to schedule the next process and we select the process with the shortest time, shortest next CPU burst time, okay? This actually is an optimal algorithm in terms of the average waiting time. It provides the minimum waiting time for a given set of processes. The difficulty here is how can we know the length of the next CPU burst for a process? So assume we know the length of the next CPU burst for each process, then the idea is very simple. You go and select the process that has the smallest length next CPU burst length and schedule that process to use the CPU. But the difficulty is how can we estimate or know the length of the next CPU request? Yes? Is process priority depends on the length of the process? Exactly. So actually here the process priority is affected from the length of the process. That means the shorter the process is, the higher the priority of that process, okay? So basically it's a priority based scheduling where the priorities are assigned according to the length of the CPU burst of the process. So let's look to an example here how this algorithm will order the process to use the CPU. Yes? What process means at the same time that we gain the average waiting time? Right. What's the another advantage of this? This provides actually minimum average waiting time. So this is the biggest advantage. So if you run this algorithm at the end, the system will have the minimum average waiting time for the processes. This is the major advantage. But it has some disadvantages as well. So it may cause starvation which has to be fixed, okay? Any other questions? All right. So let's look to an example. Assume we have those processes in the RedQ, okay? So the question is in which order the scheduler will execute those processes. So we have those processes P1, P2, P3, P4, okay? Assume they all arrived at the same time to the CPU, to the RedQ, okay? So assume we also have these burst times for these processes. So process one for example requires six milliseconds to use the CPU. Process two requires eight milliseconds, okay? Process three requires seven milliseconds. And process four requires three milliseconds, okay? So now the question is this. Which process has to be selected first, okay? And since they all arrived at the same time to the RedQ, we go and select process, which process? P4, right? So then it will be immediately start to use the CPU. It will run three milliseconds and then you go and select the next process which is P1, right? So then we run that and then we run P3 and then P4, okay, P2. So then we can compute the waiting time for each of these processes. What is the waiting time for process P4? Zero, right? So P1 will wait three milliseconds and P3 will wait nine milliseconds and P2 will wait 16 milliseconds, right? So we can add those waiting times to find the total waiting time and then we can divide that number to the number of processes and obtain the average waiting time which is seven milliseconds, okay? So this Kejnik algorithm provides the minimum waiting time, okay, for the process, minimum average waiting time. We cannot do better than this. So this is optimal in terms of the average waiting time, okay? So but the question and the difficulty was how can we determine the length of the CPU burst of a process before actually executing that burst, okay? After we execute the burst, then we know the length, right? So we can know the previous CPU burst length but how can we know the next one? So this is the question. We cannot know it, of course, exactly but we can do an estimation here by looking to the past behavior of the process, okay? We can only estimate the length. So we can do this by measuring the length of the previous CPU burst for the process and then use exponential averaging to derive from those measurements the length of the next CPU burst, okay? So assume for example, T and you know the actual length of the ant CPU burst, okay? So we are interested in computing or estimating the predicted value of the next CPU burst which we denote as tau n plus one. So we know Tn the previous CPU burst length because that burst is executed, right? The process is running in the CPU for a while and then wait it and then it will run again. So we know how much the process spent in the CPU. We know the in the previous burst. We know the length of the previous burst which is not as Tn. We are interested in the in estimating the next CPU burst, okay? Which is denote as tau n plus one. And similarly, we have estimated the previous burst length which was denoted as tau n. We know tau n, the previous estimation. We know Tn, the last measurement. Now we would like to estimate tau n plus one, okay? So for that we can just use exponential averaging based on a parameter called the rating factor called alpha. So alpha is a real number between zero and one. So tau n one can be simply estimated by using this simple formula where tau n plus one is equal to alpha Tn plus one minus alpha tau n, okay? That means tau n plus your next estimation, the next CPU burst is estimated to be alpha multiplied by the last measurement, the actual length of the last CPU burst which is not the Tn plus your previous estimation which was tau n, okay? So use alpha as the weight of this and one minus alpha as the weight of tau n, okay? So for example, we can do a simple example. Assume initially you estimate since you started the process, you did not execute it yet, you don't know any actual measurement, right? You did not do any actual CPU burst measurement so you don't know any actual value for the CPU burst. You just do an initial estimation. Let's say that you say tau zero as ten, okay? Your initial estimate is ten. So you use this initial estimate ten plus your first measurement which can be six to make your next estimate, all right? So you estimate the process length, CPU length to be ten and you start the process, okay? You do the same thing for all the process in the redicand. Assume you select this one, assume this is the shortest one, you run it for a ride and then that means you obtain its CPU, you execute the CPU burst of that process, right? So then it will block. So at that time, you exactly know how much that process has spent in the CPU. Let's say it is six time units. You estimate that to be ten but it actually spent just six milliseconds in the CPU, okay? So this is the t one actual CPU time spent by the process in the CPU, okay? So it is six and however you estimated it to be ten, okay? So this is tau zero, so this is t one. So now you will estimate the next CPU burst length, okay? Assume alpha is for example one over two, 0.5, then that means to estimate the next CPU burst, you have to multiply this by 0.5, multiply that by 0.5 and you add them together. So five plus three will make eight, okay? So eight will be the estimate of the next CPU burst, okay? So at this time for example, you estimate the next CPU burst to be eight, okay? And then you schedule your process accordingly. But next CPU burst when it comes, then the process execute next in the CPU, it will run there for a while and after it has again blocked, now the burst length will be clear at the time, it will be measured. So it can be for example four. You estimated it to be eight but it can be four, okay? So this was your estimation for tau two for example, okay? But here, so this is tau one, so at time and then however the next time CPU time has been four, okay? So now you can use this plus that actual measurement, last measurement to estimate the next CPU burst, okay? So it will be eight over two plus four over two which will be six, okay? So here you estimate the next CPU burst to be six, okay? So this blue curve is your estimation. But here this dark curve is the actual measurement values that you are performing after every CPU burst, okay? So in this way you can estimate the next CPU burst. And what will happen in reality will be, can be different from that but this will be an estimation that will be close to that, okay? So as you see the blue curve is following the actual burst length values, okay? Of course there is an error, yes? That may be possible actually but the alpha value will be is an issue here. So it is not easy to determine a good value for the alpha. Here we said it is 0.5, okay? But it can be 0.8, it can be 0.3. This is something that has to be tuned up. So what we will fix as the alpha value is an important parameter here. It can be close to zero, it can be close to one. This depends actually on the variation of the CPU burst, okay? If the CPU burst time is not varying much, you have low variance, then you can estimate, you can use an alpha that's for example close to zero, okay? But if it is varying a lot, that means the last measurement should make a big difference and so on. So then you can make it closer to one. Depends actually on the system, okay? On the process execution behavior. So it's not very easy to tune the alpha value. But its effect is different. If you set alpha close to zero, that means you are actually not counting the last measurement value much. The recent history is not counted much. You are just giving more weight to the past history, okay? If you set alpha to be equal to one or close to one, that means actually the past measurements do not have much weight. You are giving more weight to the last measurement, okay? If alpha is equal to one, for example, only the last actual CPU burst counts, okay? You are making your prediction based on that. You say that, okay, the last measurement has indicated that the last measurement was for example nine milliseconds. You just make a decision that the next CPU burst will also nine milliseconds, okay? Which can be wrong, of course, okay? So however, if you expand this formula, okay, so here what is the formula saying? You express tau n plus one based on the actual measurement tn plus previous estimation tau n. Similarly, you can expand tau n here. Tau n is equal to what? It will be equal to alpha tn minus one plus one minus alpha tau n minus one and so on, right? So you can actually expand tn, tau n, tau n minus one and so on. If you expand this formula, right, so this is a recursive definition, right, for the tau n plus one. If you expand that, as a result, you will obtain a formula for tau n plus one that just depends on some alphas, one minus alphas and actual measurements, tn, tn minus one and so on and tau zero, right? So as a result, you will have actually a formula like this for tau n plus one where you will have alpha tn plus one minus alpha multiplied by alpha tn minus one and so on, one minus alpha to the power j multiplied by alpha tn minus j and so on. And at that, we will have one minus alpha to the power n plus one tau zero, okay? So we only have tau zero appearing here and then we have the actual measurements tn, tn minus one, tn minus j appearing in the formula. That actually determines the next predicted value, tau n plus one. So if you look to the weights of these actual measurements, tn, tn minus one and so on, you can see that the weight, the weights are actually decreasing. Because alpha is a number between zero and one, so is one minus alpha, okay? So here, for example, weight in the middle has one minus alpha to the power j. That means a number between zero and one to the power j. So that means you have a very small value there, okay? So as the j is increasing, then you go towards right, okay? That means the weight of that measurement is also decreasing. So actually this term has the largest weight. The next term, tn minus one has a weight that is smaller than that because alpha multiplied by one minus alpha will be smaller than alpha, right? Because one minus alpha is smaller than one, right? So as a result, we have here the weights decreasing. Since both alpha and one minus alpha are less than or equal to one, each successive term here has less weight than its predecessor, okay? So tn minus one has less weight than tn, tn minus two has less weight than tn minus one and so on. What does it imply? It implies that the past measurements are having less effect, okay, when you make more measurements and so on, right? So the recent measurements have more weight, which makes sense, right? You give a measurement that is done 100 iterations earlier, less weight compared to a measurement that is done 10 iterations earlier, all right? Yes? Right, that's true. You are right. If you have a batch system where the program is run several times or again and again, or if you are running the programs again and again, then you can derive such a profile. But if you are running the program the first time, then you cannot derive this result automatically by the system. Of course the program can do something but you don't usually want to bother the programmer to enter that data, right? So the programmer will just type the code and then will start running but you cannot ask the programmer to enter such data to the system, okay? But what you can do if you are running the same program is if the same program is run again and again, then the system actually can derive the behavior and- The operating system can derive a profile for the program which can be used to schedule the processes, okay? So this is the exponential averaging that we can use to estimate the CPU burst lengths, okay? Next CPU burst length for the process and make the scheduling based on that. Any questions so far? Okay, so another question, another algorithm is a variation of this idea, a variation of the SGF algorithm, shortest jab-first algorithm. It's called shortest remaining jab-first, okay? So this is a preemptive version of that and this is the basic idea. So in the SGF algorithm what we were doing is when there are several processes, we select the shortest one and run it in the CPU. And then when it completes, we go to the ready queue and take the next shortest jab and run it in the CPU, okay? Assume now this happens. When you select the shortest jab, it is started to use the CPU. It is running now in the CPU, okay? Before it is terminated, it finishes, okay? Assume a new jab arrives whose CPU time is less than the remaining CPU time of the jab that is running. Then you have two choices here. One is you can continue running the same jab which is something that is done by SGF, okay? It's not preempting. Or you can just stop the current job and start running the new job that has CPU time that is less than the remaining CPU time of the job that was running, okay? So in this way, a new job that is shorter will preempt the existing or running job, okay? So therefore, this is a preemptive version of the SGF and this is what shortest remaining jab-first algorithm is doing, okay? So when a job A is running, if a new job B comes whose length is shorter than the remaining time of job A that is running, okay? Then B preempts A and B is started to run, okay? B is started to run in CPU. So this algorithm is called shortest remaining jab-first algorithm. Of course, this assumes that you know when a new job arrives, you know how much CPU it will require, okay? CPU time it will require. So let's do an example for this algorithm as well. So assume you have this process P1 through P4 in the system. So assume the process arrive at those times, okay? And these are the burst times required by those processes. So what happens now? At time 0, which job is in the system? Which process is in the system? P1, right? So we don't have any choice but run P1. So we run P1, but at time 1, a new job arrives, which is P2, right? So at time 1, P2 arrives. What's the CPU time of P2? Required CPU time is 4, right? What's the remaining CPU time of P1 at time 1? 7, right? So now this algorithm may preempt P1, stop it, and start running P2. So P2 is run now in a system that is using this algorithm. So this is the preemptive version of SGF. So P2 is run. So P2 is run until time 5. Even though, for example, at time 2 and 3, two other processor arrive to the system, P3 and P4, but their CPU times are longer than the CPU time, remaining CPU time of P2. Therefore, we do not preempt P2, okay? We continue running P2 until it terminates or it expires its CPU burst and goes to the waiting state. So now at time 5, we have each processor in the system, P1, P4, and P3, right? P1 has the remaining time to be 7, P3, 9, and P4, 5, right? So what is the, which is the job, which one is the job that has the shortest remaining time? It is P4, right? So we go and run that process now. So it will run and it will complete at time 10. So at time 10, we have P1 and P3 in the system. So P1 has the remaining time to be 7, P3 has the remaining time to be 9. Therefore, we run P1 until time 17, and then we run P3, okay? So now this will be the order of running the processes, okay? So a system using this algorithm will run the process in this order and in this manner. So now we can compute the average waiting time in this case. So what's the waiting time for P1? How much it waits in the system? Here initially, it waits, it doesn't wait. But at this time, it is suspended. It waits up to here, right? So it waits how long? Nine time minutes, right? So the waiting time, total waiting time for process P1 is nine time minutes. And for process P2, what is the waiting time? So zero, right? So P2 arrives at time one and it immediately gets the CPU and it is not waiting anymore. So the waiting time for P2 is zero. The waiting time of P4 is what? It arrives at time P4, it arrives at time three and it is scheduled at time five, so it waits just two time minutes. And waiting time for P3 is? It arrives to the system at time two and it is scheduled at time 17, so 15 time minutes, right? So we can sum these numbers to find the total waiting time and divide it by four to find the average waiting time, which is 6.5 milliseconds, okay? So this is another scheduling algorithm that is a primitive version of the previous algorithm, okay? SGF algorithm. So it is called SRJF, shortest remaining job first algorithm. Any questions? Now, a different idea for scheduling is priority scheduling, meaning that we use now priorities to make scheduling decisions. A priority number is associated with each process. We assign priorities to processes and now we give the CPU, we allocate the CPU to the process with the highest priority. So this is the algorithm, very simple. Look to the ready queue, select the process that has the highest priority and run it until it completes or until it makes IO, okay? And then select the process that has the highest priority and so on. So this algorithm will select always the highest priority job and will run it, okay? So actually the SGF algorithm that we have seen is a variation of this algorithm, is a priority based algorithm where the priorities are assigned to processes based on their CPU requirements, right? CPU burst lengths. So SGF is a priority scheduling where priority is the predicted next CPU burst time. So now we can for this, we can have preemptive versions and non-preemptive priority based algorithms. In preemptive version, what you will have a higher priority process that arrives will preempt the running one, okay? If you have a process running with some priority, if a new job arrives, process arrives to the ready queue that has a higher priority, then you will suspend the running job and start running the new job. So this is called preemptive priority based algorithm. So this preemptive version or we can have non-preemptive priority based algorithm where a job then starts to run, it will run even though a new job arrives that has a higher priority, it will not be suspended, it will run until it completes or it makes IO, okay? It blocks. Of course there's a problem with this, okay? So it can cause starvation. This is a good method to give the CPU as soon as possible to processors that have higher priorities. But the bad thing is it can starve the processors that have low priorities, okay? If you have always higher priority processing in the system, a low priority process may never get a chance to use the CPU, right? This is called starvation. Low priority process or process may never execute. So how can we solve this test? Of course there are solutions to that. Aging is one solution. As time progresses, what we can do, we can increase the priority of the processors. So if a processor has stayed very long in the system, its priority gradually increases even though it has started with a very low priority, sooner or later it will have its priority increased and at the end, it will be the process with the highest priority that will get executed, okay? Of course, it will wait a lot of time for that but it will not starve for an infinite amount of time, okay? So this is called aging. So a very important scheduling idea is round-tribbing. So this is especially very important for systems that are time sharing, that have interactive users, interactive processors, okay? So now we limit the amount of time that a process stays in the CPU with this algorithm. In the previous algorithms, all right, when a process starts using the algorithm, using the CPU, okay, it is allowed to use the CPU as long as it wants, as long as it terminates, until it terminates or until it makes IO, it blocks, right? So as long as it wants to use the CPU, it's allowed to use the CPU in the previous algorithms. If we don't have a condition for preemption, of course, if a job arrives that has the higher priority, then of course we can preempt but if this case is not occurring, okay, when a process is assigned to use the CPU, it will stay there until it terminates or it makes an IO in the previous approach that we have seen, right? But here we are limiting the time that a process stays in the CPU. So each process gets certain amount of time, okay, which we call time quantum, a small unit of CPU time that's called time quantum and a process is allowed to execute that much in the CPU continuously and then it has to be suspended, all right? This time quantum is usually 10 milliseconds or 100 milliseconds, a number between them, between these two numbers, okay? It can be at most 100 milliseconds, maybe 200 milliseconds. So a process can stay in the CPU at most that much of time, okay? So after that, time has expired, has elapsed, then the process has to be suspended, should be moved back to the ready queue and another process has to be scheduled, okay? This is the basic idea. And this way what you do, assuming if you have several processes in the ready queue, you take one process, maybe the header of the queue, run it in CPU for a while and then move it back to the ready queue. Another process takes the next process in the queue which will be the head of the queue at that moment, run it in CPU for a while and then move it back to the ready queue and so on. Instead you are limiting the amount of time that the process spends continuously in the CPU, right? So that amount of time is called time quantum. So of course it's a preemptive algorithm, you are preempting the CPU, a process is not allowed to run in the CPU for an extended amount of time and also this actually limits the response time. So a process for example that's in the back of the queue, alright, is not waiting too long to get the CPU and that waiting time, that response time is actually limited. How? If there are for example n processes in the ready queue, okay, there are n processes in the ready queue. Assume I am the process at the end of the ready queue, that means n minus one processor ahead of me and each process can spend in the CPU at most two time units. Then what is the, my waiting time, the limit? n minus one multiplied by two, right? So this is the largest amount of time that I can wait. So this is the maximum response time. So in this way we are actually limiting the amount of time that I will wait. I am guaranteed that after that much time I will have a chance to use the CPU. In another algorithm I don't have such a guarantee because a job is not limited to use the CPU at most, for at most two time units. It can use the CPU for a very long time if its CPU birth is too long. Okay, if it is five minutes it will use the CPU for five minutes and I will, I have to wait at least five minutes in the ready queue if another algorithm uses. But with RoundRemain we are limiting the response time, the waiting time in the ready queue until the next CPU service, okay? So this is the good thing about this algorithm. It limits the amount of time that the process waits in the ready queue until the next CPU service, okay? However, the total waiting time for a process which is the sum of all these waiting times during its whole lifetime can be quite large. So this algorithm is not doing to improve on that metric. This algorithm is good to improve on the response time. It guarantees you or it reduces the amount of time that you wait for your next service, CPU service. It is not minimizing the total amount of time that you are waiting in the ready queue. That algorithm is SGF algorithm. Shortest job, first algorithm performs better in that metric. The total waiting time in the ready queue can be longer in RoundRemain compared to SGF. But response time or the waiting time till the next CPU service is shorter here, okay? So this is the good thing for this algorithm and this is a very important criteria for interactive jobs because you don't want to wait too much until the next CPU service as an interactive user, okay? In an interactive system. So here an important parameter is the queue here, okay? The time quantum length. We call it also as time slice, okay? So if queue is large, what's happening? If queue is infinity, what happens? You go and take the first job in the ready queue, run it until it terminates or until it makes IO. And then you go and take the next job and run. So what is this algorithm? It is first come first served algorithm, right? So if queue gets larger and larger, that means this algorithm degenerates to FIFO, to first come first served scheduling discipline, right? But if queue is small, all right, what happens? This is the job having queue too small, then you do lots of context switches, right? So then context switch becomes a big overhead. So therefore, tuning up this parameter is very important. Therefore, queue is usually between 100 and 10 milliseconds, okay? It is not in the order of nanoseconds or microseconds. It is not in the order of seconds, but it is in the order of milliseconds so that it provides good response time and also it doesn't cause too much overhead, okay? So let's look to an example with this algorithm. Assume we have these three processes, P1, P2, P3, and they have these burst times. So P1 would like to run 24 milliseconds once it is given the CPU. P2, 3 milliseconds. P3, 3 milliseconds, okay? So now what will happen? So if you are using this round-trip and scheduling algorithm and assume the time quantum is 4, then this will be the order of running the processes. So first, assume this is the processor in the radio queue in this order. P1 is ahead of P2 and P3. So at time zero, all these processes are in the radio queue, assume. So which process we will run? We will run P1, right? So P1 will run. So how long it can run? Until it expires its time quantum, right? At most, 4 time units or 4 milliseconds. So now after 4 milliseconds, it has to be suspended, right? The kernel decides to run another process. Which process? The next process in the queue. So this will be good to the end of the queue and this will become the head of the queue and it will run now. So P2 will run until it expires its time quantum or it terminates or it blocks right here. It cannot expire totally its time quantum. Meaning that it cannot use the whole time quantum but after 3 milliseconds later, it will terminate or it will block and so on. So it will give the CPU, right? So P2 will run until time 7. So now we have to run the next process which is P3 in the radio queue, right? So we run P3 again. It just requires 3 millisecond CPU time where the time quantum is 4 milliseconds. So before expiring the time quantum actually, it will go out of the CPU. So at time 10, again the CPU is idle. So we have to make a scheduling decision and we run which process? P1 again, okay? So P1 will be at the time the only process in the radio queue. So it will be run. At time 14, we will look to the radio queue, see if there is another process. No, we will continue running P1. At time 18, we will do the same thing. See the radio queue if there is another process. No, we will continue P1 and until it terminates, okay? So this is what will happen in a system that uses this algorithm. Is the idea clear? So this algorithm provides actually a good response time. Basically a process does not wait too long until it gets the next CPU service. But this algorithm does not guarantee or does not improve or provide good average turnaround time. The total time spent by a process in the system is the total turnaround time. So that metric cannot be good when you run this algorithm. For the processes, this average turnaround time can be quite high compared to, for example, SGF or sometimes compared to FCFS algorithm. All right? So in that metric, this algorithm is not doing very good. So typically, higher average turnaround time is obtained when this algorithm is running compared to SGF. But what you have is here as better, you have better response time, okay? So as I said, time quantum is a very important metric parameter here. So it affects, for example, number of contexts which is the process will experience during its lifetime and so on. So assume we have a process that has 10 time units as its lifetime, okay? It will start, if it is the only process, it will start at time zero and run at time 10 in a system that is not applying RAR algorithm, for example. So it requires just 10 millisecond CPU time, okay? This is what this process requires, assume. So assume the time quantum is 12. Then what will happen in a system that has round trimming scheduling with quantum being 12? This process will run. Then it will run, run, run and before being able to expire the time quantum, use, totally use it, it will terminate, right? So that means during its lifetime, you will not have any context switches. But assume now the time quantum is six in that system. What will happen then? That process will start running, running, running and at time six, what will happen? A context switch should happen. Another process should run if there is available. If there is another process in the RATQ, that process should be run and later on again this process will run again, okay? So during the lifetime of the process, you will, that process will experience at least one context switch, right? And if the quantum is less, okay, let's say one millisecond, then every one millisecond, this process will experience a context switch, right? So during its lifetime, it will see, for example, nine or ten context switches at least, okay? Any questions here? So therefore, the length of the quantum determines the context switches or affects the context switches and affects the overhead that the system will have while scheduling the process. Yes? Why context switching if two processes arrive at the same time? Totally depends on who arrives first or on the priority of the process, okay? Usually the real systems are not using one algorithm like this. They combine several algorithms, priority based scheduling, round-tribbing, FCFS, multi-level queues and so on. So if two processes arrive, the system may lose the priority. If two processes arrive at the same time, then the higher priority can, priority process can be run and so on, okay? All right. Turn around time. Actually what we expect is, as I said, this algorithm is not doing very good in terms of the turnaround time, okay? It is not trying to limit that. What this algorithm is good is, it is quite fair. If you have several jobs, each nearly has the same CPU time requirement. For example, each requires 100 second or let's say 10 minutes CPU time. Then when you run this algorithm, this algorithm, the system divides the CPU among these processes in an even, fair manner, okay? But each all age process is weighted, total waiting time for each process and total turnaround time for each process can be quite large and, but they will be nearly equal to each other. So the total turnaround time or total waiting time in the system is not minimized or it may not be good with this system, with this algorithm. What will be good with this algorithm is, it will be quite fair, right? No starvation will happen. It will be fair to the processes. It will divide the CPU power evenly to the process and so on and it will also provide good response time. But the total turnaround time may not be good, okay? So what do you expect the total turnaround time to be depending on the time quantum? If the time quantum is getting larger and larger, okay, then that means this algorithm behaves more like FCFS, which may have a better turnaround time actually, all right? So as a result, when the time quantum is too large, then you expect the average turnaround time for the processes to decrease, okay? For small time quantum, you expect that to be larger. So for a particular example, we can observe such a curve actually. So assume we have this workload where we have three, four processes, each requiring that much CPU time, okay? Then what can happen? You can consider the system with various time quantum. Assume the time quantum is one, then you can compute, for example, for each process the turnaround time and then you can compute average turnaround time for the processes. It can be, for example, 11. You can then consider the time quantum to be two and again you can do your computations and compute the turnaround time for each process and then average turnaround time. You can see it to be 11.5, increased a little bit, but it is specific to this example, okay? So you can plot such a curve. As a result, what you should observe is a decreasing curve here, but depending on the particular example, you can see some increases here. But on the average, you should expect a decrease in the average turnaround time for the processes if you increase the time quantum, okay? Any questions so far? So next we will describe another scheduling approach, which is multi-level queue, okay? But before that we can have a break, 10 minutes break